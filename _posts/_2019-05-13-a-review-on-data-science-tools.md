---
layout: post
title: 'A short review on data science tools'
author: "Patrick Michl"
license: "CC BY 4.0"
license-url: "https://creativecommons.org/licenses/by/4.0/"
image: /images/back/robot.webp
categories:
  - Technology
tags:
  - AutoML
  - CAMP
---

**The prospects about the AI Revolution can be overwhelming. But although the
tension is palpable, an important stage of development still is missing:
Intelligent tools.**

[![Data Science Tools](/images/posts/data-science-tools.png)](/images/posts/data-science-tools.png)

Whereas the scientific aspects of the AI Revolution are clearly entangled with
[current advances in deep learning]({% post_url
2019-04-30-a-review-on-deep-learning %}), the jumble of data science tools and
standards at a first glance seems to be completely cluttered. Fair enough to
move through the thicket and get some orientation.

### The golden era of statistics software

Since the beginning of the programming age, the data science sector utilized
classical statistics software like
[SAS](https://www.sas.com/en_us/software/platform.html) and
[SPSS](https://www.ibm.com/analytics/spss-statistics-software). Nevertheless,
these "first generation" tools, provided some serious drawbacks that are deeply
rooted in their structure.

One issue can be found in the very nature of data science: The more you already
know (wise people call it "belief") about your data domain, the better your
estimations can be. This simple Bayesian wisdom inevitably leads to a rapidly
fragmentation of specialized approaches, that e.g. are used in Natural
Language-, Speech- or Vision processing. Of course the rigid and closed
structure of classical statistics software has not been able to keep up with
this development forever.

### Community driven open-source software

The gap between willing contributors and actual developers led to a
counter-movement within the universities and the education sector towards
democratization and open structures. One of the first projects, that may be
regarded as a "second generation" data science tool, is the statistics
programming language [R](https://www.r-project.org), which is released as [free
and open source
software](https://en.wikipedia.org/wiki/Free_and_open-source_software). Another
project, that heavily benefited from this movement was
[Python](https://www.python.org/). Also Python is a multi-purpose programming
language, it owes it's incredible popularity to a large portion to the libraries
that have emerged within this movement, comprising [SciPy](https://scipy.org/),
[Pandas](https://pandas.pydata.org/) and
[Tensorflow](https://www.tensorflow.org/).

The AI revolution was accompanied by an increasing demand of data scientists.
Thereby a further issue came apparent. The usage of statistics software, as well
as R and Python, requires a strong mathematical background and high programming
skills. On the other side a lot of people got interested in getting into this
"[sexiest job of the 21st
century](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century)",
that never learned coding in school. So the question arose, if and how data
science tools could be used by specialists of different domains.

### From visual programming to automated machine learning

In the data science community statistics and software development are not only
widely appreciated but indeed regarded as the primary must-have competences.
Nevertheless, if you look beyond the horizon and focus on specific real-world
problems, you will realize that the specialists knowledge is getting more
important, the closer you get. So in order to close this gap, a further movement
in data science evolved, that emphasizes user-friendly interfaces and visual
programming. Tools like [KXEN (now
SAP)](https://www.sap.com/germany/products/predictive-analytics.html) and
[RapidMiner](https://rapidminer.com/) aim to open the area to non-programmers by
obviating the code aspect and providing a user-friendly GUI.

This approach is awesome, since it purifies the workflow from any technical
issues and therefore accelerates the whole development process. Compared to
Python and R, however, the scope of applications and adaptability is very
limited. So once again we have a situation of competing concepts with
distinctive strengths and once again the decisive step is their fusion!

The fundamental idea behind automated machine learning is to simplify the stack

automatically train neural networks on their own datasets.



Google AutoML enables developers and engineers with very limited machine learning experience to automatically train neural networks on their own datasets.

First step towards
automating the end-to-end process of applying machine learning to real-world problems

[Explain what AutoML is]


However, the "third generation" is taking the decisive step with the concept of automated machine learning (AutoML).


### Footnotes

[^1]:
